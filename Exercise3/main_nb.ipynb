{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel, BeamSearchScorer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-11): 12 x GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set promt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'I boarded'\n",
    "\n",
    "encoded_text = tokenizer(text, return_tensors='pt')\n",
    "encoded_text = encoded_text.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decoders and outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I boarded a train from Paris to the Vatican, and arrived shortly after midnight on the sixth day of the month, and was soon in a crowded square. He told us he had just finished his evening of business when a stranger walked in on him with a sword in his hand. He asked the man what he was doing. A little girl was lying on a bench in front of another man who was waiting to leave. She looked at him with a puzzled expression. The stranger pulled out the knife and started to stab her. She said, \"No, nothing.\" The stranger then grabbed her throat, and started biting her very hand again. A little girl lay on the floor in front of him. The stranger stabbed her again.\n",
      "\n",
      "The first thing the girl said to him was: \"Don't touch me, I'm a child!\" He was silent for a moment but then said to her: \"I don't think you can do it, I don't even know your mother, she's a\n"
     ]
    }
   ],
   "source": [
    "#Default top_k\n",
    "response = model.generate(**encoded_text, max_new_tokens=200, do_sample=True, top_k=20)\n",
    "response_text = tokenizer.decode(response[0], skip_special_tokens=True)\n",
    "print(response_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I boarded at a number of the first stops on a tour last night. When I asked what a hotel was like for its staff it was said to be similar to a military base.\n",
      "\n",
      "\n",
      "In addition to the hotels and hotels here, there are a number of eateries that I haven't been to, as well as a lot of restaurants and cafes. There are a lot of small shops, but I was actually surprised to find that most of all here I went out for a quick meal in what will hopefully be as easy-going a city as Seattle.\n",
      "\n",
      "\n",
      "So there was no time for thinking about this. I was heading down to the backwaters of the lake to look for fresh water with great views of downtown Seattle as I left. I wasn't disappointed. There was no time to think too much. My first stop was a small pub called The Coffee House that sat on a well-worn corner in a quaint bar called the Watermelon Inn near the city. The food at the bar\n"
     ]
    }
   ],
   "source": [
    "#Default top_p\n",
    "response = model.generate(**encoded_text, max_new_tokens=200, do_sample=True, top_p=20)\n",
    "response_text = tokenizer.decode(response[0], skip_special_tokens=True)\n",
    "print(response_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beam search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I boarded the plane with my wife, who was staying with her husband. I told her that I was going to go to the airport, and we would take off. She said, \"What do you want to do?\" I said I wanted to get out of there.\n",
      "\n",
      "She said she wanted me to come back to my house, but I did not want her to see me. So I took off on my own. The next day, I got home and went to bed. When I woke up, my husband and I were sitting in the living room. He was trying to figure out what was wrong with me, so I asked him what he was doing and he told me he had a problem with his wife. And he said he didn't know what the problem was with him, because he wasn't doing anything wrong. It was just a matter of time before I realized that this was not the first time this had happened to me in my life. As soon as I found out that\n"
     ]
    }
   ],
   "source": [
    "#Beam search\n",
    "response = model.generate(**encoded_text, max_new_tokens=200, do_sample=True, num_beams=4, early_stopping=True, no_repeat_ngram_size=2, )\n",
    "response_text = tokenizer.decode(response[0], skip_special_tokens=True)\n",
    "print(response_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Greedy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I boarded a horse, and then I did a great deed.\n",
      "\n",
      "(2) But there is nothing like the same kind of good and pleasant kind of experience when you will seek more things than there are parts for yourself.\n",
      "\n",
      "(3) But if there were so much more which you wish for, no one knows you better, there would be no cause but to enjoy it.\n",
      "\n",
      "(4) For I wish that all things should come from one soul, but I wish that some part should remain outside the body; which is why I am sorry to say that there are some who will say, \"I will not go this way unless you go that way, though it is in your own way; but if you do not wish that you walk this way, then no one will want to think about it.\"\n",
      "\n",
      "(5) That should come from the soul, not from the body. How can this be, though what you think is that of another person; and if it\n"
     ]
    }
   ],
   "source": [
    "#Greedy\n",
    "response = model.generate(**encoded_text, max_new_tokens=200, do_sample=True)\n",
    "response_text = tokenizer.decode(response[0], skip_special_tokens=True)\n",
    "print(response_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I boarded my flight.\n",
      "\n",
      "I was only about an hour and six minutes away, but then I saw a video of the helicopter being shot up and started filming. At the time I was wondering if they were really shooting it from an elevated helicopter, but I was told not to worry.\n",
      "\n",
      "I am not sure why I thought it was so important to be able to see my friends take the plane and be able to go down that mountain. If they didn't go down the mountain, the helicopter wouldn't have any problems.\n",
      "\n",
      "With respect to the helicopter, I've heard people talking about how they had flown under a flying truck, though I don't remember how many people have done it.\n",
      "\n",
      "The helicopter has also been filmed at a hotel near the airport.\n",
      "\n",
      "I am still trying to answer questions about it and for obvious reasons it was a big mistake for the safety of every member of staff. I've also read about the danger we had at a small airport by the\n"
     ]
    }
   ],
   "source": [
    "#Sampling\n",
    "response = model.generate(**encoded_text, max_new_tokens=200, do_sample=True)\n",
    "response_text = tokenizer.decode(response[0], skip_special_tokens=True)\n",
    "print(response_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
