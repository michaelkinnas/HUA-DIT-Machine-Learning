{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel, BeamSearchScorer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-11): 12 x GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set promt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'I ate a pizza'\n",
    "\n",
    "encoded_text = tokenizer(text, return_tensors='pt')\n",
    "encoded_text = encoded_text.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decoders and outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I ate a pizza with my mom, and she's been a big fan of mine for a long time. I'm so glad I did.\"\n",
      "\n",
      "The restaurant has a long history of good food, and has had its own menu. The restaurant's menu is based on the original Italian pizza recipe that was popular in the late 19th and early 20th centuries, which was served at the restaurant.\n",
      "\n",
      "\"We've been in a lot of restaurants in the past that had pizza, but we've never been to a pizza place that was as good,\" said Joe. \"We've been to a lot of restaurants that were really good and we're really glad they were.\"\n",
      "\n",
      "The pizza was served in an old fashioned Italian style, but with the added bonus of a nice crust and the added bonus that there was a little more flavor in there.\n",
      "\n",
      "\"It was really nice, and it was really nice to be able to eat it and not have a problem with that,\" he said.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Default top_k\n",
    "response = model.generate(**encoded_text, max_new_tokens=200, do_sample=True, top_k=4)\n",
    "response_text = tokenizer.decode(response[0], skip_special_tokens=True)\n",
    "print(response_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I ate a pizza at the table and this was my favorite pizza order.\"\n",
      "\n",
      "This is what she said to me afterwards when i walked in the door:\"I'd say 'if you're not prepared for it,' I would've said'maybe this isn't what the deal is' and probably they wouldn't have done the Pizza Express,\" she said.\n",
      "\n",
      "\"The main thing when I was a kid (the whole concept of Pizza Express) was really to drive more, I didn't drive for the money, not at all, so I would get out of town and go to work or school if I could. I never would have been able to travel up Interstate 50 if I had stayed on all day with my mom because her car was off in traffic and then we would never have been able to get to my job because my boss would call me to say we're going to pay the rent and then he'd pay for my taxi or taxi driver or the driver would just pull up as I walked in\n"
     ]
    }
   ],
   "source": [
    "#Default top_p\n",
    "response = model.generate(**encoded_text, max_new_tokens=200, do_sample=True, top_p=90)\n",
    "response_text = tokenizer.decode(response[0], skip_special_tokens=True)\n",
    "print(response_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beam search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I ate a pizza, and then I went to bed,\" he said.\n",
      "\n",
      "In a statement to CBC News, the restaurant said it was aware of the incident and was working with the RCMP to find out what happened. \"Our thoughts and prayers are with those affected by this incident,\" the statement read.\n"
     ]
    }
   ],
   "source": [
    "#Beam search\n",
    "response = model.generate(**encoded_text, max_new_tokens=200, do_sample=True, num_beams=4, early_stopping=True, no_repeat_ngram_size=2, )\n",
    "response_text = tokenizer.decode(response[0], skip_special_tokens=True)\n",
    "print(response_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Greedy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I ate a pizza at a restaurant called a bar, they were open 24 hours, so when I walked in, I told my girlfriend I was going to meet with people there and she said, \"Sure, why not?\" They would tell me how many years of pizza they've had and that was a huge help. I also got a lot of advice and a lot of great tips and compliments from my friends and family, and that was really, really nice to be there. They didn't let me in on a lot because not only was the pizza wonderful, but there were always some great people there waiting for me.\n",
      "\n",
      "So, here we are, 12 years later, and it's a little bittersweet to learn I am starting my own boutique. I'm so excited to work on things I've done. It's pretty exciting. I've been through so much in my life that sometimes what you have to talk about is what you think about and I think that's what makes me feel comfortable in my\n"
     ]
    }
   ],
   "source": [
    "#Greedy\n",
    "response = model.generate(**encoded_text, max_new_tokens=200, do_sample=True)\n",
    "response_text = tokenizer.decode(response[0], skip_special_tokens=True)\n",
    "print(response_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I ate a pizza. I mean, really? Is there anything else you want me to share with you?\n",
      "\n",
      "Pizza (unfiltered): \"What? That isn't right. I haven't had pizza before. I've never had fried chicken before. Did you find out that there's nothing else on the menu?\"\n",
      "\n",
      "(He laughs.)\n",
      "\n",
      "Pizza (unfiltered): Ah, yeah. I've had fried chicken before. The best thing about fried chicken is it's very healthy, I think. Yeah...\n",
      "\n",
      "(Cut to the diner looking for another pizza.)\n",
      "\n",
      "Pizza (unfiltered): Why not?\n",
      "\n",
      "(He looks down at his plate. He spots a doughnut on the table and turns away, making an abrupt turn at one end, but before he leaves, the waiter hands him a small plastic box with a large bowl full of pizza. He holds up the box for the waitress, who takes her cue and takes a piece with a\n"
     ]
    }
   ],
   "source": [
    "#random sampling\n",
    "response = model.generate(**encoded_text, max_new_tokens=200, do_sample=True)\n",
    "response_text = tokenizer.decode(response[0], skip_special_tokens=True)\n",
    "print(response_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
