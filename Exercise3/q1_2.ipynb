{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel, BeamSearchScorer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-11): 12 x GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set promt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'I drink coffee'\n",
    "\n",
    "encoded_text = tokenizer(text, return_tensors='pt')\n",
    "encoded_text = encoded_text.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decoders and outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I drink coffee, I'm a fan of coffee. I love to drink coffee. I love to drink coffee. I love to drink coffee.\n",
      "\n",
      "But I also love to eat, so that's what I do. I eat. I eat.\n",
      "\n",
      "I'm a fan of food. I eat. I eat.\n",
      "\n",
      "But I also love to sleep, so that's what I do. I sleep. I sleep.\n",
      "\n",
      "I'm a fan of the music, so that's what I do. I love to listen. I listen.\n",
      "\n",
      "But I also love to eat, so that's what I do. I eat. I eat.\n",
      "\n",
      "I like to watch television, so that is what I do. I like to watch.\n",
      "\n",
      "But I also love to drink, so that's what I do. I drink. I drink.\n",
      "\n",
      "I love music, so that's what I do. I like to listen. I listen.\n",
      "\n",
      "But I also\n"
     ]
    }
   ],
   "source": [
    "#Default top_k\n",
    "response = model.generate(**encoded_text, max_new_tokens=200, do_sample=True, top_k=4)\n",
    "response_text = tokenizer.decode(response[0], skip_special_tokens=True)\n",
    "print(response_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I drink coffee and tea and eat pasta. I read the dictionary and do the things you didn't think of.\"\n",
      "\n",
      "In the United States, there are a great many schools where students can study to take a job they never think of taking, but those schools may not be for them. To meet the demand for a graduate position and to pursue a better career, there is a much greater focus on entrepreneurship in education, including the pursuit of a bachelor's degree and a master's. Entrepreneurship has been a highly successful business for the past 40 years, with nearly 3 times as many graduating college graduates as Americans.\n",
      "\n",
      "\"This kind of high-tech, well-paying job is a thing that doesn't exist anywhere else,\" said Tom Hockstein, chairman of the International Entrepreneurship Council, a trade group. \"Our system is full of people who want to succeed.\" Some 30 countries in the world have embraced high-tech entrepreneurship, and the US appears to be the last to see\n"
     ]
    }
   ],
   "source": [
    "#Default top_p\n",
    "response = model.generate(**encoded_text, max_new_tokens=200, do_sample=True, top_p=90)\n",
    "response_text = tokenizer.decode(response[0], skip_special_tokens=True)\n",
    "print(response_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beam search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I drink coffee and I drink tea. I don't drink beer or wine.\"\n",
      "\n",
      "\"I'm not drinking coffee, I'm drinking tea,\" he said. \"I've never been to a bar where I've had a drink. It's not like drinking a lot of beer, but it's a little bit of tea.\"\n"
     ]
    }
   ],
   "source": [
    "#Beam search\n",
    "response = model.generate(**encoded_text, max_new_tokens=200, do_sample=True, num_beams=4, early_stopping=True, no_repeat_ngram_size=2, )\n",
    "response_text = tokenizer.decode(response[0], skip_special_tokens=True)\n",
    "print(response_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Greedy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I drink coffee.\n",
      "\n",
      "I'm not a guy who's trying to hide in the shadows. So I'm saying I'm afraid to go out all the time. I don't wear makeup a lot. What's been on my mind like doing the interview? Have I learned a great deal from going through the same set on a Monday night?\n",
      "\n",
      "It was interesting to see you with the girls in the first week. Your hair was really good for you.\n",
      "\n",
      "It just felt like it needed a lot of a redone. Like me, you get a whole lot of attention from the camera and you're really into it. Not every set is all that straight forward.\n",
      "\n",
      "It's hard to get your hair done. Like I said, I love the show. People think I look like the girl and I do look like the girl, but I know what to expect now. I think everyone is expecting more from me and it kind of just came about because I'm a part of being\n"
     ]
    }
   ],
   "source": [
    "#Greedy\n",
    "response = model.generate(**encoded_text, max_new_tokens=200, do_sample=True)\n",
    "response_text = tokenizer.decode(response[0], skip_special_tokens=True)\n",
    "print(response_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I drink coffee, but I have little desire to.\n",
      "\n",
      "And if that's the case, I can't really afford to.\n",
      "\n",
      "Now to the other side of the ledger, the other case — like I said, I can't afford it. I had to start over and work on it — in other words, buy a new car. And it wasn't just my car — it was my life, and it was not in the best interest of my family or myself to move for the rest of my life to pursue this goal.\n",
      "\n",
      "I will never buy a new car, nor drive it, nor buy another car.\n",
      "\n",
      "Again, because I will save money and do my math just like I did before.\n",
      "\n",
      "And that is all there is to it.\n",
      "\n",
      "And even though I have many other things, like my children, and my parents' finances, I can't afford to lose my kids in my plan for life. My kids are too hard to care for themselves\n"
     ]
    }
   ],
   "source": [
    "#random sampling\n",
    "response = model.generate(**encoded_text, max_new_tokens=200, do_sample=True)\n",
    "response_text = tokenizer.decode(response[0], skip_special_tokens=True)\n",
    "print(response_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
